{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8eb31b7c-60d9-4ab7-b721-4c7e37b79db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/classweight_submission_Logistic4.csv\n",
      "../data/ozon_4_.ipynb\n",
      "../data/sample_submit.csv\n",
      "../data/smoto_submission_ensemble.csv\n",
      "../data/smoto_submission_lightBGM.csv\n",
      "../data/smoto_submission_Logistic.csv\n",
      "../data/submission_ensemble.csv\n",
      "../data/submission_lightBGM.csv\n",
      "../data/submission_lightBGM2.csv\n",
      "../data/submission_lightBGM2_2.csv\n",
      "../data/submission_lightBGM3.csv\n",
      "../data/submission_Logistic.csv\n",
      "../data/submission_Logistic2.csv\n",
      "../data/submission_Logistic3.csv\n",
      "../data/sumoto_submission_Logistic2.csv\n",
      "../data/sumoto_submission_Logistic3.csv\n",
      "../data/sumoto_submission_Logistic3_2.csv\n",
      "../data/sumoto_submission_Logistic3_3.csv\n",
      "../data/sumoto_submission_Logistic4.csv\n",
      "../data/sumoto_submission_Logistic4_2.csv\n",
      "../data/test.tsv\n",
      "../data/train.tsv\n",
      "../data/.ipynb_checkpoints\\ozon_4_-checkpoint.ipynb\n",
      "../data/.ipynb_checkpoints\\sample_submit-checkpoint.csv\n",
      "../data/.ipynb_checkpoints\\submission_ensemble-checkpoint.csv\n",
      "../data/.ipynb_checkpoints\\submission_lightBGM-checkpoint.csv\n",
      "../data/.ipynb_checkpoints\\submission_lightBGM3-checkpoint.csv\n",
      "../data/.ipynb_checkpoints\\submission_Logistic-checkpoint.csv\n",
      "../data/.ipynb_checkpoints\\submission_Logistic2-checkpoint.csv\n",
      "../data/.ipynb_checkpoints\\submission_Logistic3-checkpoint.csv\n",
      "../data/.ipynb_checkpoints\\test-checkpoint.tsv\n",
      "../data/.ipynb_checkpoints\\train-checkpoint.tsv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('../data/'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c24b6ef6-e994-4114-827e-b92232f296ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame._add_numeric_operations.<locals>.sum of               id  WSR0  WSR1  WSR2  WSR3  WSR4  WSR5  WSR6  WSR7  WSR8  ...  \\\n",
       "Date                                                                    ...   \n",
       "1998-04-05    94   0.4   0.5   2.1   2.2   2.5   2.4   2.1   2.9   3.6  ...   \n",
       "1998-04-11   100   0.0   0.6   0.4   0.3   0.1   0.3   0.2   1.4   2.6  ...   \n",
       "1998-04-20   109   1.8   0.3   0.1   0.1   0.1   0.2   0.2   0.7   0.9  ...   \n",
       "1998-04-23   112   0.5   0.1   0.1   0.1   0.1   0.2   0.3   0.8   1.2  ...   \n",
       "1998-04-25   114   3.1   2.4   2.4   3.0   3.4   3.4   3.9   4.5   5.5  ...   \n",
       "...          ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   \n",
       "2001-05-23  1225   0.8   0.3   0.2   0.4   0.3   1.4   0.9   1.5   1.9  ...   \n",
       "2001-06-15  1248   2.2   1.7   0.8   3.8   4.0   4.1   2.0   1.9   1.8  ...   \n",
       "2001-06-16  1249   0.4   0.4   0.1   0.1   0.0   0.4   0.5   0.6   1.3  ...   \n",
       "2001-06-18  1251   0.4   0.7   0.5   0.6   0.8   1.0   1.6   1.5   2.3  ...   \n",
       "2001-06-19  1252   0.7   0.7   0.1   0.1   0.2   0.4   0.4   0.4   0.8  ...   \n",
       "\n",
       "              U50    V50    HT50     KI     TT      SLP  SLP_  Precp  OZONE  \\\n",
       "Date                                                                          \n",
       "1998-04-05  20.91  -3.90  5755.0 -15.90  19.40  10140.0  20.0   0.00      1   \n",
       "1998-04-11  17.27 -12.27  5795.0 -12.60  24.20  10220.0  45.0   0.00      1   \n",
       "1998-04-20  20.36   2.61  5740.0  -3.50  30.60  10180.0  35.0   0.00      1   \n",
       "1998-04-23  16.78 -17.99  5680.0  -2.40  37.60  10195.0 -10.0   0.00      1   \n",
       "1998-04-25   9.22  -5.96  5790.0   7.10  35.40  10165.0 -25.0   0.00      1   \n",
       "...           ...    ...     ...    ...    ...      ...   ...    ...    ...   \n",
       "2001-05-23  17.58  -2.33  5795.0   3.40  35.70  10150.0  25.0   0.00      1   \n",
       "2001-06-15   7.11   7.01  5865.0  34.10  48.80  10150.0  50.0   3.33      1   \n",
       "2001-06-16   6.40  -5.96  5900.0   0.25  44.35  10185.0  35.0   0.00      1   \n",
       "2001-06-18  -4.00  -4.00  5900.0  -1.70  41.40  10180.0 -15.0   0.00      1   \n",
       "2001-06-19  -2.25  -3.93  5880.0  26.65  45.75  10165.0 -15.0   0.00      1   \n",
       "\n",
       "             type  \n",
       "Date               \n",
       "1998-04-05  train  \n",
       "1998-04-11  train  \n",
       "1998-04-20  train  \n",
       "1998-04-23  train  \n",
       "1998-04-25  train  \n",
       "...           ...  \n",
       "2001-05-23  train  \n",
       "2001-06-15  train  \n",
       "2001-06-16  train  \n",
       "2001-06-18  train  \n",
       "2001-06-19  train  \n",
       "\n",
       "[111 rows x 75 columns]>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_table('../data/train.tsv', index_col='Date', parse_dates=True)\n",
    "test_df = pd.read_table('../data/test.tsv', index_col='Date', parse_dates=True)\n",
    "sample_sub = pd.read_csv('../data/sample_submit.csv')\n",
    "\n",
    "# set type label\n",
    "train_df['type'] = 'train'\n",
    "test_df['type'] = 'test'\n",
    "\n",
    "# all data\n",
    "all_df = pd.concat([train_df, test_df], axis=0)\n",
    "\n",
    "# OZONEが高い日の数\n",
    "train_df[train_df[\"OZONE\"]==1.0].sum\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aad5c3d-d96a-40f1-85d0-ea6b608575a8",
   "metadata": {},
   "source": [
    "## 学習する特徴量を作成\n",
    "#### __欠損値処理__\n",
    "→全部平均値で補完\n",
    "\n",
    "#### __特徴量の削除/追加__\n",
    "なんもしない\n",
    "\n",
    "#### __データ変換__\n",
    "→とりあえず全部標準化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "308334c6-5d7e-4bf0-b7c3-b1d0c72582b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_df : \n",
      "            WSR_PK  WSR_AV  T_PK  T_AV        T85      RH85         HT85  \\\n",
      "Date                                                                       \n",
      "1998-01-01     5.5     3.1  19.1  12.5   6.700000  0.110000  1612.000000   \n",
      "1998-01-02     5.5     3.4  22.4  17.8   9.000000  0.250000  1594.500000   \n",
      "1998-01-03     5.6     3.5  22.2  18.7   9.000000  0.560000  1568.500000   \n",
      "1998-01-04     4.7     3.2  19.6  18.7   9.900000  0.890000  1546.500000   \n",
      "1998-01-05     3.7     2.3  26.0  21.1  13.539776  0.556758  1531.399585   \n",
      "...            ...     ...   ...   ...        ...       ...          ...   \n",
      "2001-06-29     3.3     1.7  30.6  25.7  17.400000  0.520000  1579.500000   \n",
      "2001-06-30     3.3     2.0  31.7  26.9  16.000000  0.840000  1561.500000   \n",
      "2001-07-01     4.1     2.0  27.9  24.8  16.500000  0.790000  1555.000000   \n",
      "2001-07-02     3.1     1.4  30.8  24.8  17.100000  0.640000  1559.500000   \n",
      "2001-07-03     2.6     1.4  30.9  26.2  16.800000  0.760000  1583.500000   \n",
      "\n",
      "                 T70      RH70         HT70  ...        HT50         KI  \\\n",
      "Date                                         ...                          \n",
      "1998-01-01 -2.300000  0.300000  3178.500000  ...  5795.00000 -12.100000   \n",
      "1998-01-02 -2.200000  0.960000  3172.000000  ...  5805.00000  14.050000   \n",
      "1998-01-03  0.900000  0.540000  3160.000000  ...  5790.00000  17.900000   \n",
      "1998-01-04  3.000000  0.770000  3145.500000  ...  5775.00000  31.150000   \n",
      "1998-01-05  5.841479  0.383645  3144.764167  ...  5815.91443   9.262858   \n",
      "...              ...       ...          ...  ...         ...        ...   \n",
      "2001-06-29  6.000000  0.600000  3205.500000  ...  5870.00000  27.800000   \n",
      "2001-06-30  5.000000  0.780000  3186.500000  ...  5850.00000  35.600000   \n",
      "2001-07-01  6.400000  0.630000  3180.000000  ...  5855.00000  32.100000   \n",
      "2001-07-02  6.700000  0.560000  3186.000000  ...  5865.00000  28.100000   \n",
      "2001-07-03  6.300000  0.860000  3210.000000  ...  5895.00000  35.500000   \n",
      "\n",
      "                   TT           SLP  Precp  T_MAX   WSR_MAX       UV85  \\\n",
      "Date                                                                     \n",
      "1998-01-01  17.900000  10330.000000   0.00   19.1  1.362542   3.970000   \n",
      "1998-01-02  29.000000  10275.000000   0.00   22.4  0.878363   9.120000   \n",
      "1998-01-03  41.300000  10235.000000   0.00   22.2  1.093558  11.060000   \n",
      "1998-01-04  51.700000  10195.000000   2.08   19.6  0.799717   8.240000   \n",
      "1998-01-05  37.227059  10164.373444   0.58   26.0  0.790524   4.028934   \n",
      "...               ...           ...    ...    ...       ...        ...   \n",
      "2001-06-29  44.800000  10190.000000   0.05   30.6  1.010372   2.560000   \n",
      "2001-06-30  49.600000  10175.000000   0.18   31.7  0.933087   2.690000   \n",
      "2001-07-01  48.200000  10155.000000   0.23   27.9  0.991559   3.780000   \n",
      "2001-07-02  45.000000  10160.000000   2.87   30.8  0.779342  -0.740000   \n",
      "2001-07-03  46.050000  10190.000000   0.00   30.9  0.708284  -4.230000   \n",
      "\n",
      "                 UV70       UV50  \n",
      "Date                              \n",
      "1998-01-01   7.300000   9.110000  \n",
      "1998-01-02  15.540000  12.230000  \n",
      "1998-01-03   8.220000  16.740000  \n",
      "1998-01-04  12.280000  19.270000  \n",
      "1998-01-05   6.599703  10.597296  \n",
      "...               ...        ...  \n",
      "2001-06-29   5.240000   7.380000  \n",
      "2001-06-30   4.810000   7.380000  \n",
      "2001-07-01   2.570000   6.380000  \n",
      "2001-07-02  -1.430000   3.480000  \n",
      "2001-07-03  -4.300000  -1.670000  \n",
      "\n",
      "[1267 rows x 22 columns]\n",
      "\n",
      "y : \n",
      "Date\n",
      "1998-01-01    0.0\n",
      "1998-01-02    0.0\n",
      "1998-01-03    0.0\n",
      "1998-01-04    0.0\n",
      "1998-01-05    0.0\n",
      "             ... \n",
      "2001-06-29    0.0\n",
      "2001-06-30    0.0\n",
      "2001-07-01    0.0\n",
      "2001-07-02    0.0\n",
      "2001-07-03    0.0\n",
      "Name: OZONE, Length: 1267, dtype: float64\n",
      "\n",
      "train_df : \n",
      "        WSR_PK    WSR_AV      T_PK      T_AV           T85          RH85  \\\n",
      "0     1.015406  0.727247 -0.935098 -1.211422 -1.400513e+00 -1.821665e+00   \n",
      "1     1.015406  1.049596 -0.482037 -0.456681 -9.295647e-01 -1.250812e+00   \n",
      "2     1.102038  1.157046 -0.509495 -0.328518 -9.295647e-01  1.321889e-02   \n",
      "3     0.322351  0.834697 -0.866453 -0.328518 -7.452807e-01  1.358801e+00   \n",
      "4    -0.543968 -0.132352  0.012212  0.013251  3.637269e-16 -1.810783e-15   \n",
      "...        ...       ...       ...       ...           ...           ...   \n",
      "2307 -0.753449 -0.901346  1.437890  1.378840  1.440302e+00 -8.156491e-01   \n",
      "2308 -0.300372 -0.415422  0.190452 -0.042983  2.132435e-01 -1.727580e+00   \n",
      "2309 -0.701733 -0.991951  1.238235  1.143104  1.217920e+00  1.421715e-01   \n",
      "2310 -0.613926 -0.785294  0.796935  0.644256 -9.037970e-02 -1.391275e-01   \n",
      "2311  0.208175 -0.357300  0.962090  0.726602  1.518748e+00 -1.137638e+00   \n",
      "\n",
      "          HT85           T70          RH70      HT70  ...            KI  \\\n",
      "0     2.171370 -2.120681e+00 -3.353340e-01  0.681069  ... -1.082313e+00   \n",
      "1     1.699921 -2.094633e+00  2.310600e+00  0.549845  ...  2.425325e-01   \n",
      "2     0.999483 -1.287150e+00  6.268239e-01  0.307585  ...  4.375862e-01   \n",
      "3     0.406804 -7.401445e-01  1.548892e+00  0.014855  ...  1.108875e+00   \n",
      "4     0.000000  2.313515e-16 -1.112719e-15  0.000000  ... -6.299729e-16   \n",
      "...        ...           ...           ...       ...  ...           ...   \n",
      "2307  0.327905  2.313515e-16 -1.112719e-15  0.000000  ... -6.299729e-16   \n",
      "2308 -0.064988  1.123064e+00 -1.457852e+00  0.241072  ... -7.906231e-01   \n",
      "2309  0.776734  8.815996e-01  2.027801e-01  1.151472  ...  8.008781e-01   \n",
      "2310  0.120381 -1.291160e-01  1.471451e-01  0.039321  ...  5.096528e-02   \n",
      "2311  1.259947  1.427674e+00 -5.387828e-01  1.741142  ...  2.191975e-01   \n",
      "\n",
      "                TT       SLP     Precp     T_MAX   WSR_MAX      UV85  \\\n",
      "0    -1.786384e+00  3.202663 -0.261979 -0.935098  0.787244 -0.007770   \n",
      "1    -7.604202e-01  2.139147 -0.261979 -0.482037 -0.559355  0.671254   \n",
      "2     3.764586e-01  1.365681 -0.261979 -0.509495  0.039145  0.927042   \n",
      "3     1.337722e+00  0.592215  1.353582 -0.866453 -0.778085  0.555227   \n",
      "4     3.940493e-15  0.000000  0.188514  0.012212 -0.803654  0.000000   \n",
      "...            ...       ...       ...       ...       ...       ...   \n",
      "2307  3.940493e-15 -0.746193 -0.261979  1.437890 -0.551892 -1.826240   \n",
      "2308 -6.087743e-01 -0.037460 -0.261979  0.190452 -0.191856 -0.824370   \n",
      "2309  5.622193e-01 -0.324312 -0.261979  1.238235 -0.051079 -0.907274   \n",
      "2310 -1.250732e-01  0.081337 -0.261979  0.796935 -0.220459 -0.186645   \n",
      "2311  4.337144e-01  0.309398 -0.261979  0.962090  0.726458 -0.390509   \n",
      "\n",
      "              UV70          UV50  month  \n",
      "0     7.486558e-02 -1.145702e-01      1  \n",
      "1     9.557672e-01  1.257713e-01      1  \n",
      "2     1.732187e-01  4.731880e-01      1  \n",
      "3     6.072551e-01  6.680803e-01      1  \n",
      "4     2.848536e-16  2.736745e-16      1  \n",
      "...            ...           ...    ...  \n",
      "2307  2.848536e-16  2.736745e-16      8  \n",
      "2308 -4.736305e-01 -3.176808e-01     10  \n",
      "2309 -1.112073e+00 -1.696713e+00      7  \n",
      "2310 -4.085442e-02 -4.100031e-02      8  \n",
      "2311 -8.746397e-01 -1.320496e+00      5  \n",
      "\n",
      "[2312 rows x 23 columns]\n",
      "\n",
      "y : \n",
      "0       0.0\n",
      "1       0.0\n",
      "2       0.0\n",
      "3       0.0\n",
      "4       0.0\n",
      "       ... \n",
      "2307    1.0\n",
      "2308    1.0\n",
      "2309    1.0\n",
      "2310    1.0\n",
      "2311    1.0\n",
      "Name: OZONE, Length: 2312, dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "def eda(all_df):\n",
    "    # データの追加,気温・風速の標準偏差\n",
    "    #1時間ごとの気温・風速を取得\n",
    "    T_data = all_df[['T0', 'T1', 'T2', 'T3', 'T4', 'T5', 'T6', 'T7', 'T8', 'T9', 'T10', 'T11', 'T12', 'T13', 'T14', 'T15', 'T16', 'T17', 'T18', 'T19', 'T20', 'T21', 'T22', 'T23']]\n",
    "    WSR_data = all_df[['WSR0', 'WSR1', 'WSR2', 'WSR3', 'WSR4', 'WSR5', 'WSR6', 'WSR7', 'WSR8', 'WSR9', 'WSR10', 'WSR11', 'WSR12', 'WSR13', 'WSR14', 'WSR15', 'WSR16', 'WSR17', 'WSR18', 'WSR19', 'WSR20', 'WSR21', 'WSR22', 'WSR23']]\n",
    "    # 行ごとの最高気温/風速を追加\n",
    "    all_df['T_MAX'] = T_data.max(axis=1)\n",
    "    all_df['WSR_MAX'] = WSR_data.std(axis=1)\n",
    "    \n",
    "    # ○○ヘクトパスカル面の風速を統一\n",
    "    all_df['UV85'] = all_df['U85'] + all_df['V85']\n",
    "    all_df['UV70'] = all_df['U70'] + all_df['V70']\n",
    "    all_df['UV50'] = all_df['U50'] + all_df['V50']\n",
    "    \n",
    "    # 各ヘクトパスカル面の気温を足す\n",
    "    # all_df['T_all'] = all_df['T85'] + all_df['T70'] + all_df['T50'] \n",
    "    \n",
    "\n",
    "    # データの削除, T0~T23\n",
    "    all_df = all_df.drop(columns=['T0', 'T1', 'T2', 'T3', 'T4', 'T5', 'T6', 'T7', 'T8', 'T9', 'T10', 'T11', 'T12', 'T13', 'T14', 'T15', 'T16', 'T17', 'T18', 'T19', 'T20', 'T21', 'T22', 'T23'])\n",
    "    # データの削除, WSR0~WSR23\n",
    "    all_df = all_df.drop(columns=['WSR0', 'WSR1', 'WSR2', 'WSR3', 'WSR4', 'WSR5', 'WSR6', 'WSR7', 'WSR8', 'WSR9', 'WSR10', 'WSR11', 'WSR12', 'WSR13', 'WSR14', 'WSR15', 'WSR16', 'WSR17', 'WSR18', 'WSR19', 'WSR20', 'WSR21', 'WSR22', 'WSR23'])\n",
    "    \n",
    "    # データの削除, SLP_\n",
    "    all_df = all_df.drop(columns=['SLP_'])\n",
    "    \n",
    "    # ○○ヘクトパスカル面の風速の各方向を削除, U85,V85,U70,...\n",
    "    all_df = all_df.drop(columns=['U85','V85','U70','V70','U50','V50'])\n",
    "    \n",
    "    # 各ヘクトパスカル面の気温を削除\n",
    "    # all_df = all_df.drop(columns=['T85','T70','T50'])\n",
    "    \n",
    "    # 各ヘクトパスカル面の高度を削除(高度は海面気圧と気温から求まる)\n",
    "    # all_df = all_df.drop(columns=['HT85','HT70','HT50'])\n",
    "    \n",
    "    # 海面気圧を削除？\n",
    "    # all_df = all_df.drop(columns=['SLP'])\n",
    "    \n",
    "    return all_df\n",
    "\n",
    "\n",
    "# 特徴量の削除/追加\n",
    "all_df = eda(all_df)\n",
    "\n",
    "# trainとtestに分けなおす\n",
    "train_df = all_df[all_df['type'] == 'train']\n",
    "test_df = all_df[all_df['type'] == 'test']\n",
    "# train正解ラベル\n",
    "y = train_df['OZONE']\n",
    "\n",
    "# 学習に不要な特徴量を削除\n",
    "train_df = train_df.drop(columns=['id', 'OZONE', 'type'])\n",
    "test_df = test_df.drop(columns=['id', 'OZONE', 'type'])\n",
    "\n",
    "# 欠損値を平均値で補完\n",
    "train_df = train_df.fillna(train_df.mean())\n",
    "test_df = test_df.fillna(test_df.mean())\n",
    "\n",
    "print(f'train_df : \\n{train_df}\\n')\n",
    "print(f'y : \\n{y}\\n')\n",
    "\n",
    "\n",
    "# データ標準化(rightGBMのときはいらない)\n",
    "scaler = StandardScaler()\n",
    "train_df = pd.DataFrame(scaler.fit_transform(train_df), index = train_df.index, columns = train_df.columns)\n",
    "test_df = pd.DataFrame(scaler.transform(test_df), index = test_df.index, columns = test_df.columns)\n",
    "\n",
    "# 時系列(月)を特徴量に追加\n",
    "train_df['month'] =  train_df.index.month\n",
    "test_df['month'] =  test_df.index.month\n",
    "\n",
    "# オーバーサンプリング\n",
    "# SMOTEの初期化と適用\n",
    "smote = SMOTE(random_state=42)\n",
    "train_df, y = smote.fit_resample(train_df, y)\n",
    "\n",
    "print(f'train_df : \\n{train_df}\\n')\n",
    "print(f'y : \\n{y}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11626f4f-6792-4c53-b5b1-2783f4c8b1eb",
   "metadata": {},
   "source": [
    "## 検証データ作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c293299a-f8e0-4f3a-a606-e74c0cf57e9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.867811963567638"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#khold\n",
    "cv = KFold(n_splits=5, random_state=0, shuffle=True)\n",
    "\n",
    "train_acc_list = []\n",
    "val_acc_list = []\n",
    "models = []\n",
    "mse_results = []\n",
    "\n",
    "# indexをDateから普通のindexに直す(kholdが使えないため)、日付は消す\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "\n",
    "scores = cross_val_score(model, train_df, y, scoring='balanced_accuracy', cv=cv, n_jobs=-1)\n",
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e04ad9-4c7e-477b-a6d3-e8d780532ac1",
   "metadata": {},
   "source": [
    "## モデルの作成と評価\n",
    "今回はロジェスティック回帰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eba39fe1-1454-4fae-9470-47c839b9590a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8182844243792325\n",
      "0.7993727235936867\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import balanced_accuracy_score,accuracy_score\n",
    "\n",
    "# KFold で学習させる\n",
    "for i ,(trn_index, val_index) in enumerate(cv.split(train_df, y)):\n",
    "    \n",
    "    print(f'Fold : {i}')\n",
    "    X_train ,X_val = train_df.loc[trn_index], train_df.loc[val_index]\n",
    "    y_train ,y_val = y[trn_index],y[val_index]\n",
    "    \n",
    "    # LigthGBM用のデータセットを定義\n",
    "    lgb_train = lgb.Dataset(X_train, y_train)\n",
    "    lgb_valid = lgb.Dataset(X_val, y_val)\n",
    "    \n",
    "    model = lgb.train(\n",
    "        params = lgb_params,         # ハイパーパラメータをセット\n",
    "        train_set = lgb_train,       # 訓練データを訓練用にセット\n",
    "        valid_sets = [lgb_train, lgb_valid],   # 訓練データとテストデータをセット\n",
    "        valid_names=['Train', 'Valid'],    # データセットの名前をそれぞれ設定\n",
    "        callbacks=[lgb.log_evaluation(period=100),lgb.early_stopping(10), lgb.record_evaluation(lgb_results)], # アウトプット\n",
    "    )\n",
    "    \n",
    "    y_pred = model.predict(X_train)\n",
    "    print(f'y_pred.sum------------------------{np.where(y_pred>=0.5, 1, 0).sum()}')\n",
    "    print(f'y_train.sum----------------------{y_train.sum()}')\n",
    "    \n",
    "    train_acc = accuracy_score(\n",
    "        y_train, np.where(y_pred>=0.5, 1, 0)\n",
    "        )\n",
    "    print(train_acc)\n",
    "    train_acc_list.append(train_acc)\n",
    "    \n",
    "    y_pred_val = model.predict(X_val)\n",
    "    val_acc = accuracy_score(\n",
    "        y_val, np.where(y_pred_val>=0.5, 1, 0)\n",
    "        )\n",
    "    print(val_acc)\n",
    "    val_acc_list.append(val_acc)\n",
    "    \n",
    "    models.append(model)\n",
    "\n",
    "print('-'*10 + 'Result' +'-'*10)\n",
    "print(f'Train_acc : {train_acc_list} , Ave : {np.mean(train_acc_list)}')\n",
    "print(f'Valid_acc : {val_acc_list} , Ave : {np.mean(val_acc_list)}')\n",
    "\n",
    "# モデルを定義し学習\n",
    "model = LogisticRegression(max_iter=3000) \n",
    "model.fit(X_train, y_train)\n",
    "print(model.score(X_train, y_train))\n",
    "\n",
    "# 訓練データに対しての予測を行い、正答率を算出\n",
    "y_pred = model.predict(X_val)\n",
    "print(balanced_accuracy_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a935d430-330b-49be-a2da-288a19fdc7b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85e74e05-f402-4d66-b811-a460adebd282",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This LogisticRegression instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m roc_curve, auc\n\u001b[1;32m----> 3\u001b[0m y_score \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m)\u001b[49m[:, \u001b[38;5;241m1\u001b[39m] \u001b[38;5;66;03m# 検証データがクラス1に属する確率\u001b[39;00m\n\u001b[0;32m      4\u001b[0m fpr, tpr, thresholds \u001b[38;5;241m=\u001b[39m roc_curve(y_true\u001b[38;5;241m=\u001b[39my_val, y_score\u001b[38;5;241m=\u001b[39my_score)\n\u001b[0;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(fpr, tpr, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroc curve (area = \u001b[39m\u001b[38;5;132;01m%0.3f\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m auc(fpr, tpr))\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1367\u001b[0m, in \u001b[0;36mLogisticRegression.predict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1341\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_proba\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m   1342\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1343\u001b[0m \u001b[38;5;124;03m    Probability estimates.\u001b[39;00m\n\u001b[0;32m   1344\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1365\u001b[0m \u001b[38;5;124;03m        where classes are ordered as they are in ``self.classes_``.\u001b[39;00m\n\u001b[0;32m   1366\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1367\u001b[0m     \u001b[43mcheck_is_fitted\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1369\u001b[0m     ovr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmulti_class \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124movr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   1370\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmulti_class \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1371\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1374\u001b[0m         )\n\u001b[0;32m   1375\u001b[0m     )\n\u001b[0;32m   1376\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ovr:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1622\u001b[0m, in \u001b[0;36mcheck_is_fitted\u001b[1;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[0;32m   1619\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not an estimator instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (estimator))\n\u001b[0;32m   1621\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_fitted(estimator, attributes, all_or_any):\n\u001b[1;32m-> 1622\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(msg \u001b[38;5;241m%\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(estimator)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m})\n",
      "\u001b[1;31mNotFittedError\u001b[0m: This LogisticRegression instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "y_score = model.predict_proba(X_val)[:, 1] # 検証データがクラス1に属する確率\n",
    "fpr, tpr, thresholds = roc_curve(y_true=y_val, y_score=y_score)\n",
    "\n",
    "plt.plot(fpr, tpr, label='roc curve (area = %0.3f)' % auc(fpr, tpr))\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', label='random')\n",
    "plt.plot([0, 0, 1], [0, 1, 1], linestyle='--', label='ideal')\n",
    "plt.legend()\n",
    "plt.xlabel('false positive rate')\n",
    "plt.ylabel('true positive rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ffa375e5-614c-4ec5-8ca6-786c21eb1343",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This LogisticRegression instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# テストデータを予測\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m test_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# 行数で繰り返し予測値を代入\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, row \u001b[38;5;129;01min\u001b[39;00m sample_sub\u001b[38;5;241m.\u001b[39miterrows():\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:351\u001b[0m, in \u001b[0;36mLinearClassifierMixin.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    338\u001b[0m \u001b[38;5;124;03mPredict class labels for samples in X.\u001b[39;00m\n\u001b[0;32m    339\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;124;03m    Vector containing the class labels for each sample.\u001b[39;00m\n\u001b[0;32m    349\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    350\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[1;32m--> 351\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(scores\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    353\u001b[0m     indices \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(scores \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mint\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:329\u001b[0m, in \u001b[0;36mLinearClassifierMixin.decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    310\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecision_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    311\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    312\u001b[0m \u001b[38;5;124;03m    Predict confidence scores for samples.\u001b[39;00m\n\u001b[0;32m    313\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;124;03m        this class would be predicted.\u001b[39;00m\n\u001b[0;32m    328\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 329\u001b[0m     \u001b[43mcheck_is_fitted\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    330\u001b[0m     xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[0;32m    332\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(X, accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1622\u001b[0m, in \u001b[0;36mcheck_is_fitted\u001b[1;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[0;32m   1619\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not an estimator instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (estimator))\n\u001b[0;32m   1621\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_fitted(estimator, attributes, all_or_any):\n\u001b[1;32m-> 1622\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(msg \u001b[38;5;241m%\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(estimator)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m})\n",
      "\u001b[1;31mNotFittedError\u001b[0m: This LogisticRegression instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "# テストデータを予測\n",
    "test_pred = model.predict(test_df)\n",
    "\n",
    "# 行数で繰り返し予測値を代入\n",
    "for index, row in sample_sub.iterrows():\n",
    "    sample_sub.iloc[index,1] = np.where(test_pred[index]>=0.5, 1, 0)\n",
    "\n",
    "# 結果を保存\n",
    "# sample_sub.to_csv(\"../data/sumoto_submission_Logistic4.csv\", index=False)\n",
    "# sample_sub.to_csv(\"../data/sumoto_submission_Logistic4_2.csv\", index=False)\n",
    "# sample_sub.to_csv(\"../data/classweight_submission_Logistic4.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9da5b8ea-871b-4fa9-a012-1cad352b51f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "223.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840318a7-023b-4104-b035-22f74d184527",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
